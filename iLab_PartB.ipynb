{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iLab- PartB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katyalrajat/UTS_ML2019_ID13132903/blob/master/iLab_PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFvWMI_dJIAl",
        "colab_type": "text"
      },
      "source": [
        "## Part B: Developing Evidence\n",
        "\n",
        "###1.\tEvaluated data challenges and selected appropriate approaches to data discovery\n",
        "\n",
        "a. Evaluated data type and data discovery via browsing.  \n",
        "\n",
        "The data type was images with varied resolution. This was a straight forward scan of the image folders. The image resolutions were varied. You can see the accurate input data from the image below to be:\n",
        "\n",
        "*   24 GB\n",
        "*   97,501 files\n",
        "*   15 Categories or classes\n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/prop.png?raw=1\">\n",
        "\n",
        "The images were also of varied resolution and varied types.For example, a tablet class image would be only close shots of a tablet with logo, while a generic class image could be a crime scene, a car or any focused object. I cannot share the actual images examples due to the sensitivity of the data.\n",
        "\n",
        "b. Identified challenge in finiding Hardware resources capable of training large image data for modelling.\n",
        "\n",
        "From my peers who have taken deep learning classes and from current common knowledge, it was known that we would need High end hardware resources with GPU, unlike common laptops to train neural networks for image recognition as it takes a lot of time. \n",
        "\n",
        "As mentioned in the blog imScreenshotage below, the Options for Hardware were:\n",
        "\n",
        "*   Use Private Cloud Computing Services AWS / Google Cloud\n",
        "*   Use UTS' research Hardware\n",
        "*   Procure New Hardware\n",
        "*   Use Personal Machines\n",
        "\n",
        "To read this blog : [Click Here](https://16-8931.ca.uts.edu.au/project-goals-and-update/) \n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/blog1.png?raw=1\">\n",
        "\n",
        "\n",
        "c. Data Sensitivity and hardware challenge\n",
        "\n",
        "The data images contained highly sensitive and confidential information about NSW Forensics. Hence it was utmost important to the client that this data is preserved within authorised systems. For that reason we aimed at utilising UTS research hardware for the i-Lab project. It was slightly tricky in the beginning as we were denied the hardware access (See email image below) as it is only granted for Research purposes. \n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/denial.png?raw=1\">\n",
        "\n",
        "\n",
        "But eventually, as I explained the purpose of iLab and the industry projects to the UTS hardware team, we all got the hardware access. You can see a homepage screenshot below.\n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/access.png?raw=1\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nYAeapvJou6",
        "colab_type": "text"
      },
      "source": [
        "###2.\tIdentified key concepts, frameworks or processes to utilise for problem solving:\n",
        "\n",
        "a. Deep Learning: Neural Networks\n",
        "It was evident from our initial team discussion and Alex's technical notes that this problem would require deep learning concepts. After browsing through the deep learning material on Deeplearning.ai and watching the stanford course on Convolutional Neural Networks, it was quite clear that the problem's in this space are solved using convolutional neural network concepts. \n",
        "\n",
        "[Introduction to convoltional Neural Networks for visual recognition](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=2&t=0s)\n",
        "\n",
        "From the above video it was found that the winners of all the famous ImageNet challenge that was one of the most famous image classificaiton challenges was a convolutional neural network each year were Convolutional Neural Networks. The 2012 AlexNet in the image below had beaten the Human accuracy for image classification. It was clear that I needed to understand deep learning and neural networks for our lab projkect.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1209/1*kiXf4aE2H-vZ7CBOjXIF0Q.png)\n",
        "\n",
        "b. Specific libraries: tensorflow, pytorch and keras\n",
        "\n",
        "These libraries were guided to me again by mentors and project partners as these are the most widely adopted for such problems. Below is a snippet from a note from Alex who takes the DeepLearning class at UTS. \n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/alex.png?raw=1\">\n",
        "\n",
        "The ever-popular deeplearning.ai course on deeplearning also uses the popular tensorflow package for neural network teaching. This was also discovered in the coursera course notes seen below.\n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/coursera.png?raw=1\">\n",
        "\n",
        "\n",
        "C. The hardware/GPU\n",
        "\n",
        "The hardware challenge requirement was clear from watching the videos on the deeplearning and reference material. This was conquered by gaining access to the UTS iHPC which has Nvidia GPU as shown in the above secitons.\n",
        "\n",
        "d. ShinyR/Html for creating a tool post image classification\n",
        "\n",
        "ShinyR has a nice interface which runs well with the R programming language. I had discovered this while building a tool during my winter break. Shiny which is convenient or html could be utilised for building a user interface if required for the project.\n",
        "\n",
        "[Here is the link](https://shiny.rstudio.com/gallery/) to the ShinyR gallery which showcases the various types of tools which can be build using Shiny.\n",
        "\n",
        "[Here is the tool](https://rajatkatyal.shinyapps.io/Job_Future/) I had built in ShinyR\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-RRoMmwWqoI",
        "colab_type": "text"
      },
      "source": [
        "### 3. Considered and applied legislation and standards for managing data in stakeholders’ context\n",
        "\n",
        "a. NDA has been signed between the students and the client.\n",
        "\n",
        "On the day of the first meeting, before revealing any sensitive informaiton about the porject a Non-Disclosure Agreement was signed between the parties. \n",
        "The students are abiding by the agreement terms specifically with respect to data security. The NDA copy cannot be shared as it is a sensitive document.\n",
        "\n",
        "b. For standard practice, the data sits only on the authorized machines, and is not be analyzed using any cloud computing services like google collaborator.\n",
        "\n",
        "Google collabor, that is the notebook in which you are currently reading this file, is a great free tool for machine learning as it adds the google cloud layer to the famous jupyter notebooks. However, for our purpose we refrain from using the google collab or any private tool for data analysis without the prior permission from the client. There is no evidence to support that such tools are not being used, but it is the ethical responsibility of the project group to utilise the approved resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuiszxndbRqC",
        "colab_type": "text"
      },
      "source": [
        "### 4. Created tailored criteria to evaluate your own professional development regarding stakeholder requirements and work as part of high-functioning teams\n",
        "\n",
        "a. Identify and select best channels to communicate effectively with the teammates and client.\n",
        "\n",
        "The channel which are used other than email for effective communicaiton are:\n",
        "\n",
        "With Client: Microsoft Teams (Screenshot below)\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/teams.png?raw=1\">\n",
        "\n",
        "\n",
        "Amongst team members: Slack (Screenshot below)\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/katyalrajat/ilab/blob/master/slak.png?raw=1\">\n",
        "\n",
        "\n",
        "Other than that we keep weekly meetings on Fridays to catch-up on the week's progress and to plan the next week.\n",
        "\n",
        "\n",
        "b. Discover best-practices while working in a team with diverse skill levels.\n",
        "\n",
        "\n",
        "Since my group-mates already have deep learning knowledge and are doing their iLab-2 while this is my iLab-1 there is a skill gap among the team. \n",
        "In orde to make best use of this skill gap, I follow a few things with the team:\n",
        "\n",
        "*   Share what I am planning to read and work on in the coming week and get any inputs comments or feedback on the process.\n",
        "*   Understand what the team is doing and get a knowledge transfer, in terms of approach used and challenges faced. \n",
        "*   Do not get confused with the technical details that you don't understand yet, rather focus on the things that help you grasp your self-developed critera and reduce the skill gap as a result.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v656O71RbncF",
        "colab_type": "text"
      },
      "source": [
        "###5. Self-developed criteria associated with: \n",
        "Deep Learning for Vision\n",
        "\n",
        "a. Read through Deep learning theory and understand it’s concepts for vision.\n",
        "\n",
        "Deep learning was identified as a key concept for the project and it is one of the key concepts in the Machine learning world. As shared earlier in order to understand the deeplearning theory and it's conepts for vision, I dod the following things:\n",
        "\n",
        "\n",
        "1.   Enrolled in the [Convolutional Neural Networks course](https://www.deeplearning.ai/deep-learning-specialization/) offered by deeplearning.ai which is a part of the 5 Deep Learning Specialisation courses. The course is in progress and is taught by one of the most renowned researchers Dr. Andrew Ng. It has been a great learning resource so far.\n",
        "\n",
        "\n",
        "2.   I went through the [Stanford Course on Convolutional Neural Network](http://cs231n.stanford) and watched it's youtube video series and went through the materials provided for class learning upto week 3.\n",
        "\n",
        "\n",
        "3. I read and did a [Personal Literature Review](https://github.com/katyalrajat/UTS_ML2019_ID13132903/blob/master/paper_review_rajat.ipynb) of the widely accredited research paper \"Gradient Based Learning Applied to Document Recognition\" by Yann LeCun, Leon Bottou, Yoshua Bengio and Patrick Haner , 1998. Reading this paper and writing the review taught me the thoretical aspects of a CNN which were re-instated while I was watching the course videos by Andre Ng.\n",
        "\n",
        "b. Implement a basic deep learning project/exercise based on image recognition\n",
        "\n",
        "This is a work in progress task as I am also combined this with my second criteria. As for a basic CNN model in Python, you can find the notebook below which is a deeplearning.ai template with self-configurable parameters in python without using popular packages like tensorflow.\n",
        "\n",
        "[Here is the notebook link](https://drive.google.com/open?id=1RDfl-tSc_1_dQLnSfePQ9A-4-zCjpZTG) : You can open it using google collaboratory.\n",
        "\n",
        "\n",
        "c. Acquire all the theoretical and practical knowledge for achieving the ilab project goals\n",
        "\n",
        "This is again an on-going excercise. Section a and Section b of this self-developed criteria are designed to help gather the base for this part.\n",
        "At the moment the theoretical knowledge is somewhat decent as evident in the literature review while the practical knowledge is somewhat lacking. The emphasis going forward would be to further the practical skills as could be tracked well in the future blogs. \n",
        "\n",
        "The other knowledge required would be to implement the model in the UTS hardware iHPC. The guidance on that is available in it's documentation seciton. Our group would also share our understanding of implementing it in the next meeting with each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvVysyTLcBiY",
        "colab_type": "text"
      },
      "source": [
        "###6. Self-developed criteria associated with: \n",
        "Python for Data Science\n",
        "\n",
        "a. Learn python for data science.\n",
        "\n",
        "The Stanford course material, The CNN course offered by deeplearning.ai are both in the Python language. In order to understand these I went through the following material:\n",
        "\n",
        "*   Alex's python notebooks for deep learning pre-work\n",
        "*   [Python Numpy tutorial by Justin Johnson](http://cs231n.github.io/python-numpy-tutorial/) \n",
        "\n",
        "*   [Python Course video on Youtube](https://www.youtube.com/watch?v=rfscVS0vtbw&t=3929s)\n",
        "\n",
        "*   [Python Practical skills Notebook](https://github.com/junjy007/UTS_ML2019_Main/blob/master/NB02_Practical_Data_Skills_ArrayOps.ipynb)\n",
        "\n",
        "These resources were really helpful in understanding the python basics and getting up to speed.\n",
        "\n",
        "b. Implement the iLab project in Python and not R\n",
        "Showcase the acquired python knowledge through blog posts/exercise.\n",
        "\n",
        "This would be an ongoing exercise. The learning steps so far are int he direction of implementing the project using Tensorflow in python as opposed to using Keras in R. \n",
        "\n",
        "As a best practice I am using Collaboratory notebooks for writing as you can easily implement python code in it, similar to the R markdown. For example you could run the codes in the cells below this section titled \"Sample Code Cell\" by clicking play button on the left side. It's downside is there is no spellcheck and formatting like MS Word, so kindly excuse the typos.\n",
        "\n",
        "There would be a blog coming this week(9) with a link to a Python Notebook showcasing Exploratory Data Analysis and a modelling exercise done in Python. The following week's blog would contain a notebook with some programming differences between Python and R along with the usual project progress.\n",
        "\n",
        "Here is the link to the blogs on cic (The link works for me, I'm not certain if it would for you) - https://16-8931.ca.uts.edu.au/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzei6PwgEIu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Sample Code cell\n",
        "\n",
        "print(\"Hello Notebook!\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p06pTFAjLCC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Sample Code cell\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "import numpy as np\n",
        "x = np.linspace(0, 10, 1000)\n",
        "plt.plot(x, np.sin(x))\n",
        "plt.plot(x, np.cos(x));"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}