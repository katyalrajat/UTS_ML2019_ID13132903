{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AT1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katyalrajat/UTS_ML2019_ID13132903/blob/master/Copy_of_AT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o6pp0RXaMQC",
        "colab_type": "text"
      },
      "source": [
        "##Draft and Experiment Area\n",
        "\n",
        "### Selecting a paper\n",
        "\n",
        "There were many interesting papers available in the paper list. After glancing through and reading the abstracts, a few paper interested me, these were:\n",
        "\n",
        "1. A Mathematical Theory of Communication \n",
        "  By C. E. SHANNON\n",
        "\n",
        "2. Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection \n",
        "  by Peter N. Belhumeur, Jo~ao P. Hespanha, and David J. Kriegman\n",
        "\n",
        "3. Generative Adversarial Nets\n",
        "  by Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,\n",
        "  Sherjil Ozairy, Aaron Courville, Yoshua Bengioz\n",
        "\n",
        "4. Gradient Based Learning Applied to Document Recognition\n",
        "  by Yann LeCun,  Leon Bottou, Yoshua Bengio and Patrick Haner\n",
        "  \n",
        "  \n",
        "  The most elegant paper with great detail seemed to be the first one by Shannon, it spoke about the process of communication via a network, on a fundamental level in binary sequence. It stated the challenges of different communcation scenarios and how to overcome them. But for this assigment, I wanted to review a paper which is more in lines with the practical applications of data sciecnce that I may encounter during/after the masters. So I choose a few papers [2-4] that were related to Deep Learning and Image recognition, as i was interested in knowing more about these topics.\n",
        "  \n",
        " While the Eigenfaces vs Fisherfaces seemed a good paper, it seemed to be talking about facial recognition techniques only and I was looking for a more geenralised concept. Finally paper 3 and 4 seemed to be the on the lines of the current state deep learning solutions. After doing a quick scan and browsing these concepts it seemed that GAN is less generic concept than Neural Networks and going through some image recognition videos like the one below from Stanford, I realised that CNN in 2012 was a break-through moment in Image recogonition and so I dedcided to read more about that.\n",
        " \n",
        " Here I would review: Gradient Based Learning Applied to Document Recognition as it seems to be the foundation for the 2012 ImageNet Classification with Deep Convolutional Neural Networks research by Alex Krizhevsky et. al\n",
        " \n",
        "\n",
        " Other resources :\n",
        "\n",
        " https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=2&t=0s\n",
        "\n",
        " https://qiita.com/Rowing0914/items/445095163bc6a58c59b5#3-gradient-backpropagation\n",
        " \n",
        " https://slideplayer.com/slide/13169533/  \n",
        " \n",
        " http://cs231n.stanford.edu/\n",
        " \n",
        " \n",
        "Sec I: Intro .\n",
        "\n",
        "Sec II: CNN .\n",
        "\n",
        "Sec III: Results and Comparison with Other Methods. \n",
        "\n",
        "Sec IV: Multi Module Systems and Graph Transformer Networks.\n",
        "\n",
        "Sec. V : Multiple Object Recognition- Heuristic Over Segmentation.\n",
        "\n",
        "Sec. VI : Global Training for Graph Transformer Networks.\n",
        "\n",
        "Sec. VII : Space displacement NN fro multiple object recognotion.\n",
        "\n",
        "Sec. VIII : Graph Transformer Networks and Transducers.\n",
        "\n",
        "Sec IX : An On Line Handwriting Recognition System .\n",
        "\n",
        "Sec X : A Check Reading System.\n",
        "\n",
        "Sec XI : Conclusions\n",
        "\n",
        " \n",
        "\n",
        "### Introduction Notes\n",
        "\n",
        "The paper aims to show the techniques by which a machine learning algorithm for pattern recogonition, using hand-written notes as an example, could outperform the traditional hand-crafted techniques.\n",
        "\n",
        "Traditional Approach :\n",
        "\n",
        "Module a. Feature Extractor: Hand-crafted and customised according to the applicaiton\n",
        "Module b. Classifier: General purpose and trainanble\n",
        "\n",
        "New approach: Use GTN instead of creating customised feature extractor for every use case\n",
        "\n",
        "\n",
        "A. Data based Classifier:\n",
        "\n",
        "***Error(Etest - Etrain) increases with more training samples and decreases with higher complexity(h)***\n",
        "Algorithms use structural risk minimization\n",
        "\n",
        "B. Gradient Based Learning: E(W) is a smooth function of W.\n",
        "\n",
        "C. Gradient Back Propagation : Gradient learning is old concept (1950s) but is now applied to machine learning algorithms like neural networks using back propagation (output to input).\n",
        "\n",
        "D. Learning in Real Handwriting Recognition Systems: \n",
        "\n",
        "*   Heuristics is the technique of separating charaters using edges.\n",
        "*   Alternately training at a whole string level utilizing a loss function\n",
        "*   Alternately use character spottinh and feed it to a GTN\n",
        "\n",
        "E Globally Trainable Systems:\n",
        "\n",
        "Traditionally system contains:\n",
        "\n",
        "*   Field Locator\n",
        "*   Field Segmenter\n",
        "*   recognizer\n",
        "*   contextual post-processor\n",
        "\n",
        "where each phase is intergrated and a subset of parameters is optimised at the last step.\n",
        "\n",
        "Globally trained system minimises the global error and uses gradient based learning approach to find a minimum with respect to all parameters. This is done by having all the functions as differentiable and continous to be able to find the minima for each parameter.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### CNN:\n",
        "\n",
        "3 Invariance properties: \n",
        "\n",
        "*   Shift\n",
        "*   Scale\n",
        "*   Distortion\n",
        "\n",
        "Architecture:\n",
        "\n",
        " Layers >> Planes (Feature maps) >> Units of same weight\n",
        " \n",
        " The Set of units' output is a Feature map.\n",
        " A single unit's dimensions is it's receptive field.\n",
        " \n",
        "An interesting property of convolutional layers is that\n",
        "if the input image is shifted the feature map output will\n",
        "be shifted by the same amount.\n",
        "\n",
        " \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyAD1ZxhbVbM",
        "colab_type": "text"
      },
      "source": [
        "## Review Report on \"Gradient Based Learning Applied to Document Recognition\" by Yann LeCun, Leon Bottou, Yoshua Bengio and Patrick Haner , 1998\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSd9lZLIa9HS",
        "colab_type": "text"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "This paper shows the advantages of using a globally trained approach to a machine learning algorithms while relying on automated learning instead of hand-crafted heuristics for recognition tasks. In this paper, the authors take the problem of document recogonition and compare the different approaches used and their accuracy results. The authors highlight the advantages of using a convolutional neural network(CNN). The CNN is trained in a gradient based approach made possible using back-propagation techniques. The authors show the advanteages of using CNN in terms of inavriance in scale, shift and distortion while explaining the architecture of a 7 layered CNN (LeNet-5).\n",
        "\n",
        "The results of experiments of a sample of 10,000 images of 32x32 pixels, show that the Boosted LeNetâˆ’4, a CNN, outperforms all other algorithms in accuracy scores while other CNNs like LeNet-5 and Support Vector Machines(SVM) perform almost as well. But the CNNs have a much lower memory usage (less than 10 times) and outperform other algorithms like SVM in computational time. The authors argue that the advantages of using this CNN architecture becomes much more evident with increase in training data sizes.\n",
        "\n",
        "The other sections of the paper explain the concept of Graph Transfer Network(GTN) using multiple modules and a back-propagation technique similar to one used in LeNet-5. The paper discusses in detail the techniques of Multiple Object recognition using heuristics over segmentation. it also discussed the Global Training scenarions in GTN in depth. \n",
        "\n",
        "Finally, the authors discuss how these concpets are applied to a cheque reading system that is live and deployed in American banks which reads over a million cheques per day.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeBEO3Tk1Aah",
        "colab_type": "text"
      },
      "source": [
        "### Content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "I really liked how the paper has effecively referenced every concept that has been introuced in order to dig deeper into it's foundations. This allows the reader to dig much deeper into something that they don't undertsand or something that they feel particularly interested in.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-h1ZILH1KL_",
        "colab_type": "text"
      },
      "source": [
        "### Innovation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rarIvWIa1MGf",
        "colab_type": "text"
      },
      "source": [
        "### Technical Quality\n",
        "\n",
        "\n",
        "Tech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn1LcrYi1PUf",
        "colab_type": "text"
      },
      "source": [
        "### Application and X-factor\n",
        "\n",
        "Talk about the 2012 imagenet compition and research based on this paper.\n",
        "Give the comparison and how many times it's been cited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "law981ws1Unn",
        "colab_type": "text"
      },
      "source": [
        "### Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyg2UC3R1ZXd",
        "colab_type": "text"
      },
      "source": [
        "### References"
      ]
    }
  ]
}